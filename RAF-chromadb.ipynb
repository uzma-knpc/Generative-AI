{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uzma-knpc/Generative-AI/blob/main/RAF-chromadb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evjGLA8Jx5k8"
      },
      "outputs": [],
      "source": [
        "# Pakistan zinda bad, we love our country.\n",
        "# 0         1     2    3  4.   5.   6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgK8e2vq6gvh",
        "collapsed": true,
        "outputId": "7b1f8602-c0cf-4768-c43f-5a6429fe689a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.29)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.10.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.29.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-google-genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-google-genai\n",
        "\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "U5a_LR0V7QEY"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "3Q5zbNgD72OA",
        "outputId": "89573664-41d1-4a39-fa67-da1aca86b7d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n",
              "                    'February 15th, 2025. Move to a newer Gemini version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n",
              "                    'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n",
              "                    'version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-exp-0801',\n",
              "       base_model_id='',\n",
              "       version='exp-0801',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='exp_1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1121',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1114',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "list(genai.list_models())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "wslvg_cS6hQG",
        "outputId": "7c43039c-0c35-4f1b-92bd-3b59df28dfbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.02854543, 0.044588115, -0.034197364, -0.004266 ... TRIMMED]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from typing import Dict #typing module provides type hints\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"What is the meaning of life?\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of single string\",\n",
        ")\n",
        "\n",
        "# # 1 input > 1 vector output\n",
        "print(str(result[\"embedding\"])[:50], \"... TRIMMED]\")\n",
        "\n",
        "#result['embedding']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LRebzTJABUh",
        "outputId": "ac7ead39-ac2e-40f1-d96f-fa8de0af3f77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(result['embedding'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whzpN01Z9hPA",
        "outputId": "fdf1b6b2-2b4b-4b3d-d9a3-f53b7fec0a84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(result['embedding'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "1ZqSNYKA84oQ",
        "outputId": "ae696306-b33b-4dc0-a3ad-ea817ccc094f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.036453027, 0.033254996, -0.03970925, -0.002628 ... TRIMMED ... 768\n",
            "[-0.01591948, 0.032582663, -0.081024624, -0.011298 ... TRIMMED ... 768\n",
            "[0.00037063024, 0.03763057, -0.122695684, -0.00951 ... TRIMMED ... 768\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "        \"What is the meaning of life?\",\n",
        "        \"How much wood would a woodchuck chuck?\",\n",
        "        \"How does the brain work?\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of list of strings\",\n",
        ")\n",
        "\n",
        "# A list of inputs > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\", len(v))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyrCQBs8AANE"
      },
      "source": [
        "# Building Vector Stores & Retreival using Chroma DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPpBBX9g-PKl",
        "outputId": "e44079ab-f700-4249-a213-9265196c4396",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w4Wd_L8zAJTn"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uxHZV_umADw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9004bbd-e37a-46fd-e599-cc6804908063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document[0]Cats are independent pets that often enjoy their own space.is\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
        "        metadata={\"source\": \"fish-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
        "        metadata={\"source\": \"bird-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "]\n",
        "print(f\"document[0]{documents[1].page_content}is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "4kWhNtJb9z5S",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -Uq langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4b6yLMNR9qOn",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a01cf00-e6d7-4b25-bdaf-45d8d8e8c8c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.24.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.27.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install  langchain-community\n",
        "\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",\n",
        "                                          google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "# embeddings.embed_query(\"What's our Q1 revenue?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "H6v2VV9lBNlb"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4F_AqazDjvc",
        "outputId": "ef31a1d8-f127-4cf1-8c1d-972f1837a837",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "list(dir(vectorstore))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV6SYPkLCUZf",
        "outputId": "2ee11a25-4a5f-46f0-b71c-11a2a788df15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7b8777423130>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enYsspQlCVTx",
        "outputId": "974e578c-e901-42a0-87f4-3eec5a277624"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              " Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "vectorstore.similarity_search(\"cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhUxC04ODcB_",
        "outputId": "08ae467f-6495-4f09-d0af-b3e6e7420a1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              " Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "await vectorstore.asimilarity_search(\"cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqdDbqlqD66I",
        "outputId": "4bf5b7ab-c4db-4b4b-d2d7-8c1b5e9bdc15",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              "  0.6390674114227295),\n",
              " (Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              "  0.8766832947731018),\n",
              " (Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              "  0.8958533406257629),\n",
              " (Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.'),\n",
              "  0.93742835521698)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Note that providers implement different scores; Chroma here\n",
        "# returns a distance metric that should vary inversely with\n",
        "# similarity.\n",
        "\n",
        "vectorstore.similarity_search_with_score(\"cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "M5wF724BDNb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916b623e-922b-4660-edf6-600f28a1355e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              " Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "embedding = embeddings.embed_query(\"cat\")# convert cat into vector\n",
        "\n",
        "vectorstore.similarity_search_by_vector(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fVH5rbdBFGiR",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97206f26-f29b-45fb-befa-2bad11b28e77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02929222583770752,\n",
              " -0.036574799567461014,\n",
              " -0.043439045548439026,\n",
              " -0.07810205221176147,\n",
              " -0.0037615408655256033,\n",
              " 0.009293069131672382,\n",
              " -0.01828901655972004,\n",
              " -0.026278767734766006,\n",
              " 0.0257037952542305,\n",
              " 0.04369331896305084,\n",
              " 0.021304260939359665,\n",
              " 0.004027269314974546,\n",
              " -0.006600249093025923,\n",
              " -0.015647996217012405,\n",
              " 0.031169898808002472,\n",
              " -0.015230076387524605,\n",
              " 0.03932645171880722,\n",
              " 0.05131302401423454,\n",
              " -0.0035581118427217007,\n",
              " -0.028116988018155098,\n",
              " 0.003778817830607295,\n",
              " 0.020366402342915535,\n",
              " -0.003293826477602124,\n",
              " 0.006887518800795078,\n",
              " 0.030619945377111435,\n",
              " -0.017671264708042145,\n",
              " 0.05062692239880562,\n",
              " -0.06273413449525833,\n",
              " -0.007996084168553352,\n",
              " 0.04244242236018181,\n",
              " -0.039237722754478455,\n",
              " 0.026849912479519844,\n",
              " -0.07410523295402527,\n",
              " 0.011468383483588696,\n",
              " 0.015611913055181503,\n",
              " 0.00010844393545994535,\n",
              " 1.2158683603047393e-05,\n",
              " -0.02252042479813099,\n",
              " 0.007573829963803291,\n",
              " 0.042349569499492645,\n",
              " 0.019335489720106125,\n",
              " -0.03577505424618721,\n",
              " -0.022801458835601807,\n",
              " -0.011311780661344528,\n",
              " 0.029966626316308975,\n",
              " -0.026657279580831528,\n",
              " 0.08644696325063705,\n",
              " -0.013627002947032452,\n",
              " -0.008488963358104229,\n",
              " -0.06853323429822922,\n",
              " 0.05227426066994667,\n",
              " -0.0060148644261062145,\n",
              " 0.04300200566649437,\n",
              " -0.030362606048583984,\n",
              " -0.004763374105095863,\n",
              " 0.0039228773675858974,\n",
              " 0.013957781717181206,\n",
              " 0.019847765564918518,\n",
              " -0.051605433225631714,\n",
              " -0.020686166360974312,\n",
              " 0.05097489431500435,\n",
              " 0.04642561450600624,\n",
              " -0.015827806666493416,\n",
              " 0.09266787767410278,\n",
              " -0.0005819964571855962,\n",
              " 0.02814594842493534,\n",
              " -0.056586477905511856,\n",
              " 0.07260590046644211,\n",
              " 0.025367293506860733,\n",
              " -0.05389779061079025,\n",
              " -0.025423049926757812,\n",
              " -0.00708032725378871,\n",
              " 0.018178943544626236,\n",
              " -0.003001702483743429,\n",
              " -0.03648105636239052,\n",
              " -0.05695660039782524,\n",
              " -0.050360314548015594,\n",
              " 0.01655804179608822,\n",
              " 0.002850661752745509,\n",
              " -0.0014378040796145797,\n",
              " 0.06385394185781479,\n",
              " -0.05373085290193558,\n",
              " 0.0016316574765369296,\n",
              " -0.024560471996665,\n",
              " -0.04939849674701691,\n",
              " 0.025740956887602806,\n",
              " -0.04572173207998276,\n",
              " 0.013489814475178719,\n",
              " 0.01791849546134472,\n",
              " 0.03458639606833458,\n",
              " -0.012449878267943859,\n",
              " 0.0040658642537891865,\n",
              " 0.008815455250442028,\n",
              " -0.07024208456277847,\n",
              " -0.0053595928475260735,\n",
              " 0.03684692457318306,\n",
              " 0.011036412790417671,\n",
              " 0.020443059504032135,\n",
              " -0.002539959968999028,\n",
              " -0.03708593547344208,\n",
              " -0.006225928198546171,\n",
              " -0.03348155319690704,\n",
              " 0.006482250988483429,\n",
              " 0.01458744890987873,\n",
              " 0.04241238161921501,\n",
              " 0.0276632159948349,\n",
              " -0.027709070593118668,\n",
              " 0.06638238579034805,\n",
              " 0.0005420540692284703,\n",
              " -0.014394544064998627,\n",
              " -0.04385816305875778,\n",
              " 0.02845783531665802,\n",
              " -0.03109300509095192,\n",
              " -0.021298276260495186,\n",
              " 0.02755032293498516,\n",
              " 0.03372158482670784,\n",
              " -0.0025966560933738947,\n",
              " 0.07989365607500076,\n",
              " 0.031309451907873154,\n",
              " 0.01759524643421173,\n",
              " -0.011320714838802814,\n",
              " -0.0034418683499097824,\n",
              " 0.052721984684467316,\n",
              " 0.02790743298828602,\n",
              " 0.004964560270309448,\n",
              " -0.008490187115967274,\n",
              " -0.010170131921768188,\n",
              " 0.04334954172372818,\n",
              " 0.01820482686161995,\n",
              " 0.03442766144871712,\n",
              " -0.05067143216729164,\n",
              " -0.04434310644865036,\n",
              " 0.020175734534859657,\n",
              " 0.03794877976179123,\n",
              " 0.09717931598424911,\n",
              " 0.07054132223129272,\n",
              " 0.06673621386289597,\n",
              " 0.006230505649000406,\n",
              " 0.048908624798059464,\n",
              " 0.020417694002389908,\n",
              " -0.010305408388376236,\n",
              " 0.021937545388936996,\n",
              " 0.015721328556537628,\n",
              " -0.0067252181470394135,\n",
              " 0.010000228881835938,\n",
              " 0.03585487976670265,\n",
              " -0.035547930747270584,\n",
              " -0.028349004685878754,\n",
              " 0.01306662056595087,\n",
              " 0.01115395873785019,\n",
              " 0.005755281075835228,\n",
              " 0.02689969725906849,\n",
              " -0.035748016089200974,\n",
              " 0.047647006809711456,\n",
              " 0.09305670857429504,\n",
              " -0.009371648542582989,\n",
              " -0.03488652780652046,\n",
              " 0.023100238293409348,\n",
              " 0.02019582688808441,\n",
              " 0.02077443338930607,\n",
              " 0.049827612936496735,\n",
              " 0.027514774352312088,\n",
              " 0.028289280831813812,\n",
              " 0.04119783267378807,\n",
              " -0.002022388158366084,\n",
              " -0.07114310562610626,\n",
              " 0.0007514340686611831,\n",
              " 0.023190937936306,\n",
              " 0.013926985673606396,\n",
              " 0.027006613090634346,\n",
              " 0.02008603699505329,\n",
              " 0.019250327721238136,\n",
              " -0.0572158619761467,\n",
              " -0.04840702936053276,\n",
              " -0.020089425146579742,\n",
              " -0.06750108301639557,\n",
              " -0.025601740926504135,\n",
              " -0.029224999248981476,\n",
              " -0.01374809443950653,\n",
              " -0.042624082416296005,\n",
              " -0.010292282328009605,\n",
              " -0.029132181778550148,\n",
              " 0.0007789600058458745,\n",
              " 0.028386782854795456,\n",
              " 0.00922212190926075,\n",
              " -0.026937590911984444,\n",
              " 0.06457024812698364,\n",
              " -0.004292016848921776,\n",
              " -0.03390887379646301,\n",
              " 0.002545148367062211,\n",
              " -0.02683519385755062,\n",
              " -0.013821636326611042,\n",
              " -0.04320071265101433,\n",
              " 0.008732803165912628,\n",
              " -0.0021046623587608337,\n",
              " 0.021386070176959038,\n",
              " -0.010239917784929276,\n",
              " 0.009384458884596825,\n",
              " 0.0077479989267885685,\n",
              " -0.05080944299697876,\n",
              " 0.022075224667787552,\n",
              " 0.09745211899280548,\n",
              " -0.022912826389074326,\n",
              " 0.007962336763739586,\n",
              " 0.01660371758043766,\n",
              " 0.017167627811431885,\n",
              " 0.055798936635255814,\n",
              " -0.0720345601439476,\n",
              " -0.012983742170035839,\n",
              " 0.012170589528977871,\n",
              " -0.006716995500028133,\n",
              " -0.02160070836544037,\n",
              " -0.02934006042778492,\n",
              " 0.028048299252986908,\n",
              " 0.025326229631900787,\n",
              " -0.018942352384328842,\n",
              " 0.06285969913005829,\n",
              " -0.0033893329091370106,\n",
              " 0.00304798549041152,\n",
              " -0.01760452426970005,\n",
              " -0.04052438214421272,\n",
              " -0.010775207541882992,\n",
              " -0.029462475329637527,\n",
              " 0.017051566392183304,\n",
              " -0.009798677638173103,\n",
              " 0.06359448283910751,\n",
              " -0.033738888800144196,\n",
              " -0.003418285632506013,\n",
              " 0.0024584708735346794,\n",
              " -0.047764409333467484,\n",
              " -0.023981837555766106,\n",
              " 0.03389821574091911,\n",
              " 0.011959818191826344,\n",
              " -0.054226282984018326,\n",
              " 0.06756877154111862,\n",
              " -0.006056755781173706,\n",
              " 0.028505491092801094,\n",
              " -0.01201650034636259,\n",
              " 0.02898331545293331,\n",
              " 0.03713388368487358,\n",
              " -0.004748228937387466,\n",
              " 0.015280451625585556,\n",
              " 0.061618153005838394,\n",
              " 0.05657714605331421,\n",
              " -0.0464823916554451,\n",
              " -0.042489420622587204,\n",
              " -0.0034628668799996376,\n",
              " 0.005139355082064867,\n",
              " -0.013854569755494595,\n",
              " 0.03391667827963829,\n",
              " -0.01882685348391533,\n",
              " -0.03340086713433266,\n",
              " 0.009056789800524712,\n",
              " 0.018644869327545166,\n",
              " -0.01124679483473301,\n",
              " 0.02293292246758938,\n",
              " -0.07004982978105545,\n",
              " 0.012805637903511524,\n",
              " 0.016492318361997604,\n",
              " -0.004432620480656624,\n",
              " 0.023550089448690414,\n",
              " -0.0008547353208996356,\n",
              " -0.030292470008134842,\n",
              " -0.021300524473190308,\n",
              " -0.039018165320158005,\n",
              " 0.0236158799380064,\n",
              " 0.03158041462302208,\n",
              " -0.022946294397115707,\n",
              " 0.010825103148818016,\n",
              " 0.007078987080603838,\n",
              " 0.017755409702658653,\n",
              " 0.012945292517542839,\n",
              " 0.045665040612220764,\n",
              " -0.006389062851667404,\n",
              " -0.02699265442788601,\n",
              " 0.01781199499964714,\n",
              " -0.01920904591679573,\n",
              " 0.02162974514067173,\n",
              " -0.0023843070957809687,\n",
              " 0.005219814367592335,\n",
              " 0.032657381147146225,\n",
              " 0.05459006503224373,\n",
              " 0.061197467148303986,\n",
              " -0.03083120286464691,\n",
              " -0.027343152090907097,\n",
              " -0.03953421488404274,\n",
              " -0.07637694478034973,\n",
              " -0.0017762990901246667,\n",
              " 0.013309735804796219,\n",
              " -0.010174950584769249,\n",
              " -0.05412814021110535,\n",
              " -0.02749955840408802,\n",
              " -0.022882264107465744,\n",
              " -0.019579876214265823,\n",
              " -0.05052972212433815,\n",
              " 0.04708736762404442,\n",
              " -0.03154604509472847,\n",
              " 0.05416004732251167,\n",
              " 0.035725533962249756,\n",
              " -0.002318854443728924,\n",
              " -0.0012104958295822144,\n",
              " -0.02239806205034256,\n",
              " 0.016315339133143425,\n",
              " -0.06587446480989456,\n",
              " 0.03089497983455658,\n",
              " -0.004003857262432575,\n",
              " -0.0188248660415411,\n",
              " -0.05119946971535683,\n",
              " 0.02311544679105282,\n",
              " -0.0014477587537840009,\n",
              " -0.005283830687403679,\n",
              " -0.012841609306633472,\n",
              " -0.0849551409482956,\n",
              " 0.024611545726656914,\n",
              " 0.060005851089954376,\n",
              " 0.011588014662265778,\n",
              " -0.02059302292764187,\n",
              " 0.03403549641370773,\n",
              " -0.03022872470319271,\n",
              " 0.008280151523649693,\n",
              " 0.026516275480389595,\n",
              " 0.0662943422794342,\n",
              " 0.018308477476239204,\n",
              " -0.002221874427050352,\n",
              " 0.005441292654722929,\n",
              " 0.014312398619949818,\n",
              " 0.007983753457665443,\n",
              " 0.059627290815114975,\n",
              " 0.005756284110248089,\n",
              " -0.003744822693988681,\n",
              " -0.021140048280358315,\n",
              " -0.005587774328887463,\n",
              " -0.08254797756671906,\n",
              " 0.05293247103691101,\n",
              " 0.012084797024726868,\n",
              " 0.015018858946859837,\n",
              " -0.02587655931711197,\n",
              " -0.007552071008831263,\n",
              " -0.019686007872223854,\n",
              " 0.015589060261845589,\n",
              " 0.05685296282172203,\n",
              " 0.00026341938064433634,\n",
              " -0.05450553447008133,\n",
              " -0.025961099192500114,\n",
              " 0.024005433544516563,\n",
              " 0.008744923397898674,\n",
              " -0.038997355848550797,\n",
              " 0.020851366221904755,\n",
              " 0.07441598176956177,\n",
              " 0.03395938500761986,\n",
              " 0.01976812444627285,\n",
              " 0.04723121598362923,\n",
              " -0.02825033664703369,\n",
              " -0.05900168791413307,\n",
              " 0.0013059182092547417,\n",
              " -0.04178868606686592,\n",
              " 0.00383971375413239,\n",
              " 0.0009462764719501138,\n",
              " 0.030149368569254875,\n",
              " -0.039684832096099854,\n",
              " -0.0031054469291120768,\n",
              " 0.12611481547355652,\n",
              " -0.03183506801724434,\n",
              " -0.007057562470436096,\n",
              " 0.0010755674447864294,\n",
              " 0.07268338650465012,\n",
              " 0.038311269134283066,\n",
              " 0.016332527622580528,\n",
              " -0.05000946670770645,\n",
              " 0.027737963944673538,\n",
              " -0.025122232735157013,\n",
              " -0.03972293436527252,\n",
              " -0.013362165540456772,\n",
              " -0.0040360079146921635,\n",
              " -0.025659075006842613,\n",
              " -0.03304355591535568,\n",
              " -0.04394889622926712,\n",
              " -0.029294930398464203,\n",
              " -0.0025398682337254286,\n",
              " 0.021508291363716125,\n",
              " -0.0073372116312384605,\n",
              " -0.01409986987709999,\n",
              " 0.07888252288103104,\n",
              " 0.02617546357214451,\n",
              " -0.001422528293915093,\n",
              " -0.05447925627231598,\n",
              " 0.059733375906944275,\n",
              " 0.04343947023153305,\n",
              " 0.013480985537171364,\n",
              " -0.0050396183505654335,\n",
              " 0.02038385719060898,\n",
              " 0.03691567853093147,\n",
              " 0.027115274220705032,\n",
              " 0.057692669332027435,\n",
              " -0.0028271423652768135,\n",
              " 0.03437532112002373,\n",
              " -0.02070930227637291,\n",
              " -0.04771123453974724,\n",
              " 0.033339973539114,\n",
              " -0.023116538301110268,\n",
              " 0.023302288725972176,\n",
              " 0.008311568759381771,\n",
              " -0.05618688091635704,\n",
              " -0.0048520867712795734,\n",
              " -0.02521146461367607,\n",
              " -0.0219968743622303,\n",
              " 0.03398356959223747,\n",
              " -0.02069287933409214,\n",
              " -0.03528968617320061,\n",
              " 0.02236722782254219,\n",
              " 0.03659650310873985,\n",
              " 0.03925786912441254,\n",
              " 0.04185250774025917,\n",
              " -0.03139546886086464,\n",
              " -0.06762349605560303,\n",
              " -0.043847206979990005,\n",
              " 0.07439811527729034,\n",
              " -0.022050796076655388,\n",
              " -0.006761097349226475,\n",
              " -0.00969469640403986,\n",
              " 0.0031334327068179846,\n",
              " 0.01466370653361082,\n",
              " -0.03170104697346687,\n",
              " -0.006943302694708109,\n",
              " -0.02009451575577259,\n",
              " -0.02893707901239395,\n",
              " 0.050012458115816116,\n",
              " -0.01612958312034607,\n",
              " -0.012767544947564602,\n",
              " 0.032213035970926285,\n",
              " 0.05461806803941727,\n",
              " 0.03065614216029644,\n",
              " -0.024870414286851883,\n",
              " -0.002331770723685622,\n",
              " 0.0002194595872424543,\n",
              " -0.052690573036670685,\n",
              " 0.0336327962577343,\n",
              " 0.01696506142616272,\n",
              " -0.06694192439317703,\n",
              " 0.014884889125823975,\n",
              " 0.013919013552367687,\n",
              " -0.006842507515102625,\n",
              " 0.020941399037837982,\n",
              " -0.04037300497293472,\n",
              " -0.06882398575544357,\n",
              " -0.04741472378373146,\n",
              " -0.016836857423186302,\n",
              " -0.0234761293977499,\n",
              " 0.05586487427353859,\n",
              " -0.12151248753070831,\n",
              " 0.012122038751840591,\n",
              " -0.04056679457426071,\n",
              " -0.016673943027853966,\n",
              " -0.09400852769613266,\n",
              " -0.003977067768573761,\n",
              " -0.013291645795106888,\n",
              " 0.025510041043162346,\n",
              " 0.03204268217086792,\n",
              " -0.021338602527976036,\n",
              " 0.018751831725239754,\n",
              " -0.04550538584589958,\n",
              " -0.02691807597875595,\n",
              " -0.011393683962523937,\n",
              " -0.06467961519956589,\n",
              " 0.035110846161842346,\n",
              " -0.05113460496068001,\n",
              " 0.06513066589832306,\n",
              " -0.0023309250827878714,\n",
              " 0.031635936349630356,\n",
              " 0.023260798305273056,\n",
              " -0.018168678507208824,\n",
              " -0.04376827925443649,\n",
              " 0.03120868280529976,\n",
              " 0.0051058270037174225,\n",
              " -0.05021902918815613,\n",
              " -0.0016480244230479002,\n",
              " -0.051410745829343796,\n",
              " -0.03088420256972313,\n",
              " 0.02336064912378788,\n",
              " -0.019537484273314476,\n",
              " 0.015222972258925438,\n",
              " 0.00038945619598962367,\n",
              " 0.03258678317070007,\n",
              " 0.011256001889705658,\n",
              " -0.011818323284387589,\n",
              " -0.019382981583476067,\n",
              " -0.008255326189100742,\n",
              " -0.0500483438372612,\n",
              " -0.01316983625292778,\n",
              " 0.05315835773944855,\n",
              " -0.03102416917681694,\n",
              " -0.024938000366091728,\n",
              " -0.023385299369692802,\n",
              " -0.04796814173460007,\n",
              " -0.010241152718663216,\n",
              " -0.03153641149401665,\n",
              " -0.001260725548490882,\n",
              " 0.07300177216529846,\n",
              " 0.05316145718097687,\n",
              " 0.04462053254246712,\n",
              " -0.0017320798942819238,\n",
              " -0.01651734486222267,\n",
              " -0.02304207533597946,\n",
              " -0.02968018501996994,\n",
              " 0.037391047924757004,\n",
              " -0.08819548785686493,\n",
              " 0.010384474880993366,\n",
              " 0.01709962636232376,\n",
              " -0.009272082708775997,\n",
              " -0.016829796135425568,\n",
              " 0.0037393718957901,\n",
              " 0.002070564776659012,\n",
              " -0.02799990214407444,\n",
              " -0.008861458860337734,\n",
              " 0.026529500260949135,\n",
              " -0.009900261647999287,\n",
              " 0.021483395248651505,\n",
              " 0.0074669294990599155,\n",
              " 0.017550412565469742,\n",
              " 0.020520789548754692,\n",
              " 0.08845438063144684,\n",
              " 0.0022455714643001556,\n",
              " -0.11058229207992554,\n",
              " -0.03064563125371933,\n",
              " -0.016946768388152122,\n",
              " -0.04783090949058533,\n",
              " 0.01065419428050518,\n",
              " 0.030740050598978996,\n",
              " -0.00994311273097992,\n",
              " 0.028786292299628258,\n",
              " -0.01818842440843582,\n",
              " 0.11708815395832062,\n",
              " -0.0848311185836792,\n",
              " -0.029734360054135323,\n",
              " -0.0076088379137218,\n",
              " 0.00096678122645244,\n",
              " 0.014339099638164043,\n",
              " 0.026879610493779182,\n",
              " -0.004602436907589436,\n",
              " 0.026821957901120186,\n",
              " 0.03557203710079193,\n",
              " -0.06900465488433838,\n",
              " -0.006960354745388031,\n",
              " 0.024220634251832962,\n",
              " -0.01601981744170189,\n",
              " 0.0146948816254735,\n",
              " 0.038742899894714355,\n",
              " -0.09593509882688522,\n",
              " 0.010353317484259605,\n",
              " 0.0031934715807437897,\n",
              " -0.006115491036325693,\n",
              " -0.003475538920611143,\n",
              " -0.01578637957572937,\n",
              " -0.0012283400865271688,\n",
              " 0.0089072585105896,\n",
              " 4.528198769548908e-05,\n",
              " -0.006613324861973524,\n",
              " -0.027557723224163055,\n",
              " 0.008021911606192589,\n",
              " 0.02362615428864956,\n",
              " -0.02177279256284237,\n",
              " -0.04214520379900932,\n",
              " 0.03382056578993797,\n",
              " -0.03502974659204483,\n",
              " 0.08114144951105118,\n",
              " -0.004505871329456568,\n",
              " -0.0160555187612772,\n",
              " 0.04869610071182251,\n",
              " 0.040311504155397415,\n",
              " 0.016680506989359856,\n",
              " -0.008057785220444202,\n",
              " 0.053766872733831406,\n",
              " 0.0775088220834732,\n",
              " -0.01963500864803791,\n",
              " 0.024764543399214745,\n",
              " 0.009333955124020576,\n",
              " -0.054251592606306076,\n",
              " -0.009866309352219105,\n",
              " 0.02614212967455387,\n",
              " 0.03174455091357231,\n",
              " 0.047875307500362396,\n",
              " -0.008851802907884121,\n",
              " 0.009899184107780457,\n",
              " 0.05808722972869873,\n",
              " -0.03831883892416954,\n",
              " 0.08402685821056366,\n",
              " 0.0024334173649549484,\n",
              " -0.036129530519247055,\n",
              " 0.03877534717321396,\n",
              " -0.01774711161851883,\n",
              " -0.04993116855621338,\n",
              " -0.016420112922787666,\n",
              " -0.021672697737812996,\n",
              " 0.0006256684428080916,\n",
              " -0.031935106962919235,\n",
              " -0.017563819885253906,\n",
              " 0.05755101889371872,\n",
              " 0.020390203222632408,\n",
              " -0.005602652672678232,\n",
              " -0.01773175783455372,\n",
              " 0.02737738937139511,\n",
              " -0.053599096834659576,\n",
              " 0.09221651405096054,\n",
              " -0.07000534981489182,\n",
              " 0.028421977534890175,\n",
              " 0.031234467402100563,\n",
              " 0.011065180413424969,\n",
              " -0.012011735700070858,\n",
              " -0.036323465406894684,\n",
              " 0.018471475690603256,\n",
              " -0.007785013876855373,\n",
              " -0.061907537281513214,\n",
              " 0.01833350770175457,\n",
              " -0.036468617618083954,\n",
              " -0.06044640764594078,\n",
              " 0.0036616576835513115,\n",
              " 0.03781869262456894,\n",
              " 0.03936611860990524,\n",
              " -0.034093547612428665,\n",
              " -0.020702078938484192,\n",
              " -0.03406063839793205,\n",
              " -0.030083246529102325,\n",
              " 0.005056299734860659,\n",
              " 0.02274744212627411,\n",
              " 0.05317668616771698,\n",
              " -0.007975942455232143,\n",
              " -0.03699727728962898,\n",
              " -0.060023386031389236,\n",
              " 0.07209637761116028,\n",
              " 0.03209066018462181,\n",
              " 0.007382146082818508,\n",
              " 0.008116722106933594,\n",
              " -0.02587979845702648,\n",
              " 0.00035446329275146127,\n",
              " -0.027088014408946037,\n",
              " 0.03941614553332329,\n",
              " 0.03274963051080704,\n",
              " -0.014991660602390766,\n",
              " 0.04699632525444031,\n",
              " -0.0023704860359430313,\n",
              " -0.08589570969343185,\n",
              " -0.021864639595150948,\n",
              " 0.051345422863960266,\n",
              " 0.027989156544208527,\n",
              " -0.005867442116141319,\n",
              " 0.09395608305931091,\n",
              " 0.03563661873340607,\n",
              " -0.0719342976808548,\n",
              " -0.03489920496940613,\n",
              " 0.025151319801807404,\n",
              " -0.04674594849348068,\n",
              " 0.016895940527319908,\n",
              " 0.0077423215843737125,\n",
              " 0.03268846869468689,\n",
              " 0.029399001970887184,\n",
              " 0.03827030956745148,\n",
              " -0.03390421345829964,\n",
              " -0.028514733538031578,\n",
              " 0.03732261806726456,\n",
              " -0.010475702583789825,\n",
              " -0.07103735208511353,\n",
              " -0.0015156067674979568,\n",
              " -0.0030658370815217495,\n",
              " -0.012048495002090931,\n",
              " 0.01895497925579548,\n",
              " -0.005656491965055466,\n",
              " -0.05740531161427498,\n",
              " -0.07097987830638885,\n",
              " 0.011376050300896168,\n",
              " 0.03440764173865318,\n",
              " -0.041365835815668106,\n",
              " 0.08464425057172775,\n",
              " 0.07736539840698242,\n",
              " -0.004022393375635147,\n",
              " 0.02795066125690937,\n",
              " 0.05764603987336159,\n",
              " -0.03699757158756256,\n",
              " 0.03632821515202522,\n",
              " -0.05586398020386696,\n",
              " 0.020035438239574432,\n",
              " -0.03887365013360977,\n",
              " -0.05157625302672386,\n",
              " -0.03048066608607769,\n",
              " 0.03377668559551239,\n",
              " 0.028511853888630867,\n",
              " 0.031228728592395782,\n",
              " 0.0329151526093483,\n",
              " -0.0018826451851055026,\n",
              " -0.0030598395969718695,\n",
              " -0.05109196901321411,\n",
              " 0.036555640399456024,\n",
              " -0.006562482099980116,\n",
              " 0.0004008545074611902,\n",
              " -0.007473305333405733,\n",
              " 0.0642491802573204,\n",
              " 0.01540466956794262,\n",
              " -0.04889751225709915,\n",
              " -0.0003070653765462339,\n",
              " -0.02408495731651783,\n",
              " 0.04815119504928589,\n",
              " -0.004594200290739536,\n",
              " 0.009051150642335415,\n",
              " -0.017469309270381927,\n",
              " -0.016343526542186737,\n",
              " -0.02512200176715851,\n",
              " 0.028593366965651512,\n",
              " 0.01939602568745613,\n",
              " -0.0015036978293210268,\n",
              " -0.029326457530260086,\n",
              " 0.007704002317041159,\n",
              " 0.002678931225091219,\n",
              " -0.04473113268613815,\n",
              " -0.03680801019072533,\n",
              " 0.02072680927813053,\n",
              " 0.01905970647931099,\n",
              " -0.07806970924139023,\n",
              " 0.02169770561158657,\n",
              " 0.018956679850816727,\n",
              " -0.012120461091399193,\n",
              " 0.054624054580926895,\n",
              " 0.0027132348623126745,\n",
              " 0.0064826845191419125,\n",
              " 0.042504146695137024,\n",
              " -0.03782033920288086,\n",
              " -0.014204706065356731,\n",
              " 0.031780973076820374,\n",
              " -0.01599445566534996,\n",
              " 0.03203373774886131,\n",
              " -0.010328681208193302,\n",
              " -0.028592249378561974,\n",
              " 0.021742764860391617,\n",
              " -0.03267428278923035,\n",
              " 0.007221005391329527,\n",
              " 0.05834919586777687,\n",
              " -0.04493192583322525,\n",
              " 0.07210516184568405,\n",
              " 0.010005165822803974,\n",
              " 0.03878357261419296,\n",
              " 0.0031408737413585186,\n",
              " -0.040734127163887024,\n",
              " -0.023466235026717186,\n",
              " 0.0011344288941472769,\n",
              " 0.02398352511227131,\n",
              " 0.06681656092405319,\n",
              " -0.0047651976346969604,\n",
              " -0.03369012847542763,\n",
              " 0.014887274242937565,\n",
              " 0.0007901812787167728,\n",
              " -0.013704579323530197,\n",
              " 0.007171441335231066,\n",
              " -0.07727205008268356,\n",
              " -0.028690818697214127,\n",
              " -0.011292573995888233,\n",
              " 0.04746345803141594,\n",
              " 0.014319051057100296,\n",
              " -0.023520687595009804,\n",
              " 0.013395950198173523,\n",
              " -0.03353353589773178,\n",
              " -0.028342464938759804,\n",
              " -0.021615101024508476,\n",
              " -0.05620591342449188,\n",
              " 0.05097908154129982,\n",
              " 0.025719713419675827,\n",
              " -0.02589293010532856,\n",
              " 0.023553408682346344,\n",
              " -0.005722298286855221,\n",
              " 0.0010978636564686894,\n",
              " 0.05852082744240761]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJBBUPFvFkym"
      },
      "source": [
        "# Retrievers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ndnSdfyoEsfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee26804f-797f-4913-c6c0-26d1e9801559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result\n",
        "\n",
        "retriever.batch([\"cat\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KJLP_WTbGxXP"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "B5Qg_8mtGExp"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
        "                             api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vEIe1ORnGv5P"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "rKGDcuBQI63Z"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Sc2yWh5BJJuR"
      },
      "outputs": [],
      "source": [
        "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFCGSNa3Jn5j",
        "outputId": "7b9610be-cc79-4456-98b2-0e782b071436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tell me about the type of animals\n",
            "content='Based on the provided text, the type of animal discussed is rabbits.  They are described as social animals.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-421d9d3c-8625-494b-bf07-461cacd3af13-0' usage_metadata={'input_tokens': 58, 'output_tokens': 23, 'total_tokens': 81, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ],
      "source": [
        "query1=\"tell me about the type of animals\"\n",
        "response = rag_chain.invoke(query1)\n",
        "\n",
        "print(f\"Agent Query:{query1}\")\n",
        "Print(f\"LLM \")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}